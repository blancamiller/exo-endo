{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "# Variable keeps track of gradients to be able to do grad descent\n",
    "# Variable is a tensor: a matrix with at least 3 dimensions \n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perpectron: a single linear neuron \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(1,1) # weight applied \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x) #fully connected layer with one input-one output\n",
    "        return x # output is linear with no activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# verify the contents of your network\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also inspect the parameters of our network. The parameters are automatically optimized by the network; but of course, hyperparameters such as the learning rate are tuned by humans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.9794]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.8240], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "# inspect network parameters\n",
    "print(list(net.parameters())) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because out network is linear the output is Ax + b = ([weight x input] + bias). The above values are the A and b that our network used to initialize: \n",
    "- -0.7240 (random) weight\n",
    "- -0.4475 bias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.9028]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# create a random number, a tensor, with single dimension \n",
    "# setting requires_grad=T optimizes the variable\n",
    "input = Variable(torch.randn(1,1,1), requires_grad=True)\n",
    "print(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0601]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# now, put this number through the network\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.76513806"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ax + b = output\n",
    "(-0.9794 * -0.0601) + -0.8240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.41378135"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-0.0669 * -0.5085) + -0.4478"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function & optimizer using SGD\n",
    "import torch.optim as optim \n",
    " \n",
    "# least squares loss: \"square\" gives us the magnitude of the error\n",
    "def criterion(out, label):\n",
    "    return (label - out)**2\n",
    "\n",
    "# For each training example, SGD adjusts the available parameters\n",
    "# based on how they affected the gradient of the error, and back-\n",
    "# propogates gradients and updates through the network\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Goal:__ teach the network how to treble a number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# approximate q-values of actions for current state  \n",
    "from torch import nn \n",
    "\n",
    "class Network(nn.Module): # class to track nn architecture\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Inputs to hidden layer: linear transformation \n",
    "        # 30 inputs; 20 outputs\n",
    "        self.hidden = nn.Linear(30,20) \n",
    "        \n",
    "        # Output layer: linear transformation - 20 inputs; 1 output  \n",
    "        # Does the size of the output depend on the # of actions?\n",
    "        self.output = nn.Linear(20,1)\n",
    "        \n",
    "        # Define sigmoid activation and softmax output \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass the input tensor through each of our operations\n",
    "        x = self.hidden(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.output(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
